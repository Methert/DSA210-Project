{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821fbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "shoppers_data = pd.read_csv(\"online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962e3326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows:\n",
      "   Administrative  Administrative_Duration  Informational  \\\n",
      "0               0                      0.0              0   \n",
      "1               0                      0.0              0   \n",
      "2               0                      0.0              0   \n",
      "3               0                      0.0              0   \n",
      "4               0                      0.0              0   \n",
      "\n",
      "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "0                     0.0               1                 0.000000   \n",
      "1                     0.0               2                64.000000   \n",
      "2                     0.0               1                 0.000000   \n",
      "3                     0.0               2                 2.666667   \n",
      "4                     0.0              10               627.500000   \n",
      "\n",
      "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
      "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
      "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
      "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
      "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
      "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
      "\n",
      "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
      "0        1       1            1  Returning_Visitor    False    False  \n",
      "1        2       1            2  Returning_Visitor    False    False  \n",
      "2        1       9            3  Returning_Visitor    False    False  \n",
      "3        2       2            4  Returning_Visitor    False    False  \n",
      "4        3       1            4  Returning_Visitor     True    False  \n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(shoppers_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae2b94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Administrative           12330 non-null  int64  \n",
      " 1   Administrative_Duration  12330 non-null  float64\n",
      " 2   Informational            12330 non-null  int64  \n",
      " 3   Informational_Duration   12330 non-null  float64\n",
      " 4   ProductRelated           12330 non-null  int64  \n",
      " 5   ProductRelated_Duration  12330 non-null  float64\n",
      " 6   BounceRates              12330 non-null  float64\n",
      " 7   ExitRates                12330 non-null  float64\n",
      " 8   PageValues               12330 non-null  float64\n",
      " 9   SpecialDay               12330 non-null  float64\n",
      " 10  Month                    12330 non-null  object \n",
      " 11  OperatingSystems         12330 non-null  int64  \n",
      " 12  Browser                  12330 non-null  int64  \n",
      " 13  Region                   12330 non-null  int64  \n",
      " 14  TrafficType              12330 non-null  int64  \n",
      " 15  VisitorType              12330 non-null  object \n",
      " 16  Weekend                  12330 non-null  bool   \n",
      " 17  Revenue                  12330 non-null  bool   \n",
      "dtypes: bool(2), float64(7), int64(7), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(shoppers_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1722d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Administrative  Administrative_Duration  Informational  \\\n",
      "count    12330.000000             12330.000000   12330.000000   \n",
      "mean         2.315166                80.818611       0.503569   \n",
      "std          3.321784               176.779107       1.270156   \n",
      "min          0.000000                 0.000000       0.000000   \n",
      "25%          0.000000                 0.000000       0.000000   \n",
      "50%          1.000000                 7.500000       0.000000   \n",
      "75%          4.000000                93.256250       0.000000   \n",
      "max         27.000000              3398.750000      24.000000   \n",
      "\n",
      "       Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "count            12330.000000    12330.000000             12330.000000   \n",
      "mean                34.472398       31.731468              1194.746220   \n",
      "std                140.749294       44.475503              1913.669288   \n",
      "min                  0.000000        0.000000                 0.000000   \n",
      "25%                  0.000000        7.000000               184.137500   \n",
      "50%                  0.000000       18.000000               598.936905   \n",
      "75%                  0.000000       38.000000              1464.157214   \n",
      "max               2549.375000      705.000000             63973.522230   \n",
      "\n",
      "        BounceRates     ExitRates    PageValues    SpecialDay  \\\n",
      "count  12330.000000  12330.000000  12330.000000  12330.000000   \n",
      "mean       0.022191      0.043073      5.889258      0.061427   \n",
      "std        0.048488      0.048597     18.568437      0.198917   \n",
      "min        0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.014286      0.000000      0.000000   \n",
      "50%        0.003112      0.025156      0.000000      0.000000   \n",
      "75%        0.016813      0.050000      0.000000      0.000000   \n",
      "max        0.200000      0.200000    361.763742      1.000000   \n",
      "\n",
      "       OperatingSystems       Browser        Region   TrafficType  \n",
      "count      12330.000000  12330.000000  12330.000000  12330.000000  \n",
      "mean           2.124006      2.357097      3.147364      4.069586  \n",
      "std            0.911325      1.717277      2.401591      4.025169  \n",
      "min            1.000000      1.000000      1.000000      1.000000  \n",
      "25%            2.000000      2.000000      1.000000      2.000000  \n",
      "50%            2.000000      2.000000      3.000000      2.000000  \n",
      "75%            3.000000      2.000000      4.000000      4.000000  \n",
      "max            8.000000     13.000000      9.000000     20.000000  \n"
     ]
    }
   ],
   "source": [
    "print(shoppers_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3f0168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(shoppers_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb0c664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Shape: (12330, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Shape:\", shoppers_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab67a83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "Administrative               int64\n",
      "Administrative_Duration    float64\n",
      "Informational                int64\n",
      "Informational_Duration     float64\n",
      "ProductRelated               int64\n",
      "ProductRelated_Duration    float64\n",
      "BounceRates                float64\n",
      "ExitRates                  float64\n",
      "PageValues                 float64\n",
      "SpecialDay                 float64\n",
      "Month                       object\n",
      "OperatingSystems             int64\n",
      "Browser                      int64\n",
      "Region                       int64\n",
      "TrafficType                  int64\n",
      "VisitorType                 object\n",
      "Weekend                       bool\n",
      "Revenue                       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData types:\")\n",
    "print(shoppers_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ed885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n",
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# 2. Check for missing values , there is no missing values in the dataset since the sum of missing values is 0 and as seen in the output of the info() method\n",
    "print(\"\\nMissing values per column:\")\n",
    "missing_values = shoppers_data.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"Total missing values: {missing_values.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0f5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 125\n",
      "Removed 125 duplicate rows. New shape: (12205, 18)\n"
     ]
    }
   ],
   "source": [
    "# 3. Check for duplicates\n",
    "duplicates = shoppers_data.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "if duplicates > 0:\n",
    "    shoppers_data = shoppers_data.drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"Removed {duplicates} duplicate rows. New shape: {shoppers_data.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18cbc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Handle missing values (if any) , since the dataset has no missing values, this step is not necessary. However, if there were missing values, we could handle them as follows:\n",
    "# For numeric columns - replace with median\n",
    "numeric_cols = shoppers_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_cols:\n",
    "    if shoppers_data[col].isnull().sum() > 0:\n",
    "        median_value = shoppers_data[col].median()\n",
    "        shoppers_data[col] = shoppers_data[col].fillna(median_value)\n",
    "        print(f\"Filled missing values in {col} with median: {median_value}\")\n",
    "\n",
    "# For categorical columns - replace with mode , since the dataset has no missing values, this step is not necessary. However, if there were missing values, we could handle them as follows:\n",
    "categorical_cols = shoppers_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if shoppers_data[col].isnull().sum() > 0:\n",
    "        mode_value = shoppers_data[col].mode()[0]\n",
    "        shoppers_data[col] = shoppers_data[col].fillna(mode_value)\n",
    "        print(f\"Filled missing values in {col} with mode: {mode_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee070c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Transformations and Feature Engineering\n",
    "\n",
    "# 5.1 Convert 'Month' to numerical for analysis\n",
    "month_map = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'June': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "shoppers_data['Month_Num'] = shoppers_data['Month'].map(month_map)\n",
    "\n",
    "# 5.2 Create a season feature\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "shoppers_data['Season'] = shoppers_data['Month_Num'].apply(get_season)\n",
    "\n",
    "# 5.3 Calculate total time on site\n",
    "shoppers_data['Total_Duration'] = (\n",
    "    shoppers_data['Administrative_Duration'] + \n",
    "    shoppers_data['Informational_Duration'] + \n",
    "    shoppers_data['ProductRelated_Duration']\n",
    ")\n",
    "\n",
    "# 5.4 Calculate time per page for each page type\n",
    "shoppers_data['Admin_Time_Per_Page'] = shoppers_data.apply(\n",
    "    lambda x: x['Administrative_Duration'] / x['Administrative'] if x['Administrative'] > 0 else 0, \n",
    "    axis=1\n",
    ")\n",
    "shoppers_data['Info_Time_Per_Page'] = shoppers_data.apply(\n",
    "    lambda x: x['Informational_Duration'] / x['Informational'] if x['Informational'] > 0 else 0, \n",
    "    axis=1\n",
    ")\n",
    "shoppers_data['Product_Time_Per_Page'] = shoppers_data.apply(\n",
    "    lambda x: x['ProductRelated_Duration'] / x['ProductRelated'] if x['ProductRelated'] > 0 else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 5.5 Calculate total pages viewed\n",
    "shoppers_data['Total_Pages_Viewed'] = (\n",
    "    shoppers_data['Administrative'] + \n",
    "    shoppers_data['Informational'] + \n",
    "    shoppers_data['ProductRelated']\n",
    ")\n",
    "\n",
    "# 5.6 Create an engagement score\n",
    "shoppers_data['Engagement_Score'] = (\n",
    "    shoppers_data['Total_Duration'] * 0.4 + \n",
    "    shoppers_data['Total_Pages_Viewed'] * 0.4 + \n",
    "    (1 - shoppers_data['BounceRates']) * 0.1 + \n",
    "    (1 - shoppers_data['ExitRates']) * 0.1\n",
    ")\n",
    "\n",
    "# 5.7 Calculate pages per minute (browsing intensity)\n",
    "shoppers_data['Pages_Per_Minute'] = shoppers_data.apply(\n",
    "    lambda x: x['Total_Pages_Viewed'] / (x['Total_Duration']/60) if x['Total_Duration'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 5.8 Create bounce rate categories\n",
    "def categorize_bounce(rate):\n",
    "    if rate < 0.2:\n",
    "        return 'Low'\n",
    "    elif rate < 0.6:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "        \n",
    "shoppers_data['Bounce_Category'] = shoppers_data['BounceRates'].apply(categorize_bounce)\n",
    "\n",
    "# 5.9 Create exit rate categories\n",
    "def categorize_exit(rate):\n",
    "    if rate < 0.2:\n",
    "        return 'Low'\n",
    "    elif rate < 0.6:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "        \n",
    "shoppers_data['Exit_Category'] = shoppers_data['ExitRates'].apply(categorize_exit)\n",
    "\n",
    "# 5.10 Encode visitor type as binary features\n",
    "shoppers_data['Is_Returning'] = shoppers_data['VisitorType'].apply(\n",
    "    lambda x: 1 if x == 'Returning_Visitor' else 0\n",
    ")\n",
    "shoppers_data['Is_New'] = shoppers_data['VisitorType'].apply(\n",
    "    lambda x: 1 if x == 'New_Visitor' else 0\n",
    ")\n",
    "\n",
    "# 5.11 Normalize numeric features using min-max scaling\n",
    "# Define columns to normalize\n",
    "numeric_features = [\n",
    "    'Administrative', 'Administrative_Duration', \n",
    "    'Informational', 'Informational_Duration',\n",
    "    'ProductRelated', 'ProductRelated_Duration', \n",
    "    'BounceRates', 'ExitRates', 'PageValues',\n",
    "    'Total_Duration', 'Total_Pages_Viewed',\n",
    "    'Engagement_Score', 'Pages_Per_Minute'\n",
    "]\n",
    "\n",
    "# Apply min-max normalization\n",
    "for col in numeric_features:\n",
    "    col_min = shoppers_data[col].min()\n",
    "    col_max = shoppers_data[col].max()\n",
    "    # Avoid division by zero\n",
    "    if col_max - col_min > 0:\n",
    "        shoppers_data[f'{col}_Norm'] = (shoppers_data[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        shoppers_data[f'{col}_Norm'] = 0\n",
    "        print(f\"Warning: {col} has min=max, normalization set to 0\")\n",
    "\n",
    "# 5.12 Create a binary indicator for weekend\n",
    "shoppers_data['Is_Weekend'] = shoppers_data['Weekend'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94515936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After transformations, dataset shape: (12205, 45)\n",
      "\n",
      "New features added:\n",
      "Month_Num, Season, Total_Duration, Admin_Time_Per_Page, Info_Time_Per_Page, Product_Time_Per_Page, Total_Pages_Viewed, Engagement_Score, Pages_Per_Minute, Bounce_Category, Exit_Category, Is_Returning, Is_New, Is_Weekend\n"
     ]
    }
   ],
   "source": [
    "# 6. Check the transformed data\n",
    "print(\"\\nAfter transformations, dataset shape:\", shoppers_data.shape)\n",
    "print(\"\\nNew features added:\")\n",
    "new_features = [\n",
    "    'Month_Num', 'Season', 'Total_Duration', 'Admin_Time_Per_Page', \n",
    "    'Info_Time_Per_Page', 'Product_Time_Per_Page', 'Total_Pages_Viewed',\n",
    "    'Engagement_Score', 'Pages_Per_Minute', 'Bounce_Category', 'Exit_Category',\n",
    "    'Is_Returning', 'Is_New', 'Is_Weekend'\n",
    "]\n",
    "print(\", \".join(new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1bae5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for outliers in key metrics:\n",
      "Total_Duration: 922 outliers detected (7.55%)\n",
      "Total_Pages_Viewed: 971 outliers detected (7.96%)\n",
      "Engagement_Score: 918 outliers detected (7.52%)\n"
     ]
    }
   ],
   "source": [
    "# 7. Look for outliers in key metrics\n",
    "print(\"\\nChecking for outliers in key metrics:\")\n",
    "key_metrics = ['Total_Duration', 'Total_Pages_Viewed', 'Engagement_Score']\n",
    "for col in key_metrics:\n",
    "    Q1 = shoppers_data[col].quantile(0.25)\n",
    "    Q3 = shoppers_data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = shoppers_data[(shoppers_data[col] < lower_bound) | (shoppers_data[col] > upper_bound)]\n",
    "    print(f\"{col}: {len(outliers)} outliers detected ({len(outliers)/len(shoppers_data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae598c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed data saved to 'processed_online_shoppers_intention.csv'\n"
     ]
    }
   ],
   "source": [
    "# 8. Saving the processed dataset\n",
    "shoppers_data.to_csv('processed_online_shoppers_intention.csv', index=False)\n",
    "print(\"\\nProcessed data saved to 'processed_online_shoppers_intention.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e973f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics of key features:\n",
      "       Total_Duration  Total_Pages_Viewed  Engagement_Score\n",
      "count    12205.000000        12205.000000      12205.000000\n",
      "mean      1323.454242           34.893240        543.532809\n",
      "std       2043.871589           46.627336        833.585514\n",
      "min          0.000000            0.000000          0.160000\n",
      "25%        231.666667            9.000000         97.385714\n",
      "50%        690.958333           20.000000        285.665128\n",
      "75%       1643.958333           42.000000        675.981531\n",
      "max      69921.647230          746.000000      28152.856045\n"
     ]
    }
   ],
   "source": [
    "# 9. Show summary statistics of the processed data\n",
    "print(\"\\nSummary statistics of key features:\")\n",
    "print(shoppers_data[key_metrics].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a91414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Preparation Summary:\n",
      "- Initial dataset: 12205 rows, 31 columns\n",
      "- Missing values handled: 0\n",
      "- Duplicates removed: 125\n",
      "- New features created: 14\n",
      "- Final dataset: 12205 rows, 45 columns\n"
     ]
    }
   ],
   "source": [
    "# 10. Summary of the preparation steps of the dataset \n",
    "print(\"\\nData Preparation Summary:\")\n",
    "print(f\"- Initial dataset: {shoppers_data.shape[0]} rows, {shoppers_data.shape[1] - len(new_features)} columns\")\n",
    "print(f\"- Missing values handled: {missing_values.sum()}\")\n",
    "print(f\"- Duplicates removed: {duplicates}\")\n",
    "print(f\"- New features created: {len(new_features)}\")\n",
    "print(f\"- Final dataset: {shoppers_data.shape[0]} rows, {shoppers_data.shape[1]} columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
